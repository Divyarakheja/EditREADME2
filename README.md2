# **Variational Autoencoders (VAE) using Frey Face Dataset**
This repository contains code to implement Variational Autoencoders (VAE) using the Frey Face dataset and to sample points from the learned distribution by varying different latent variables to show that the network has learned meaningful latent variables.

## Requirements
To run the code in this repository, you need the following dependencies:

- Python (3.x)
- TensorFlow
- Keras
- NumPy
- Matplotlib
- scikit-learn

The code was developed and tested in Google Colab, which already provides most of the required libraries. However, if you are running the code in a different environment, make sure to install the dependencies before executing the notebook.

You can install the required packages using the following command:

**pip install tensorflow keras numpy scikit-learn matplotlib**

## Documentation
The main code implementation can be found in the notebook "DL_Assign3_Ques2.ipynb." This notebook contains the Python code to implement Variational Autoencoders, load the Frey Face dataset, train the VAE model, and sample points from the learned distribution by varying different latent variables. The notebook includes comments explaining each step of the code.

## Download Dataset
The Frey Face dataset is used for training and evaluation. To run the code, you need to download the dataset and ensure it is available in the "Freyface Dataset" directory. The dataset can be downloaded from the following link: Frey Face Dataset

## Directory Hierarchy
```
│   VAE
│   ├── src
│   │   ├── DL_Assign3_Ques2.ipynb
│   Data
│   ├── Freyface Dataset
```  
**src**: source codes of the SAE

The directory structure is organized as follows:

The "SAE" directory contains the source code and the main notebook.
The "src" directory inside "SAE" contains the "DL_Assign3_Ques1.ipynb" notebook, which contains the implementation of Sparse Autoencoders and k-means clustering.

The "Dataset" directory contains the downloaded MNIST dataset.
Inside the "Dataset" directory, the "mnist" folder stores the extracted MNIST dataset files.

## Implementation Details
## Sparse Autoencoders (AE)

The implementation of Sparse Autoencoders is done in Python using TensorFlow and Keras libraries. The code is provided in the "DL_Assign3_Ques1.ipynb" notebook.

## The steps include:

Importing the required libraries.

* Downloading and extracting the MNIST dataset.
* Loading and preprocessing the MNIST dataset.
* Defining and training the Sparse Autoencoder model with specified hyperparameters.
* Extracting embeddings from the encoder part of the autoencoder.
* Calculating the Mean Squared Error (MSE) as the reconstruction error.

## K-means Clustering

After training the Sparse Autoencoder, k-means clustering is applied to the embeddings. The code uses scikit-learn's KMeans class to perform the clustering.

## Evaluation

To evaluate the performance of the k-means algorithm, the available labels in the dataset are used. The cluster labels obtained from k-means are mapped to the actual predicted labels using the training data.

The clustering accuracy is calculated for both the training and test sets.

## Results
The following results are obtained from the implementation:

## Loss Chart
The loss chart for the training and testing data during the training of the Sparse Autoencoder is shown below. This chart provides insights into the training progress and convergence of the model.

## Clustering Accuracy
The clustering accuracy for the training and testing data is calculated using k-means clustering on the embeddings generated by the Sparse Autoencoder. The accuracy measures how well the clustering algorithm groups similar digits together based on the available labels in the dataset.

Training Clustering Accuracy: 60.75  %

Testing Clustering Accuracy: 61.25 %

## Reconstruction Error
The reconstruction error is calculated as the Mean Squared Error (MSE) between the original images and their corresponding reconstructed images. It indicates how well the Sparse Autoencoder can reconstruct the input images.

Reconstruction Error (MSE) on Test Set: 0.01605

## Running the Code
To run the code, follow these steps:

* Open the "DL_Assign3_Ques1.ipynb" notebook in Google Colab or any
Python environment with the required libraries installed.

* Download the MNIST dataset from the provided link and ensure it is located in the "mnist" folder inside the "Dataset" directory.

* Execute the code cells in the notebook sequentially by clicking on the "Play" button (triangle) or pressing Shift + Enter.

* Observe the outputs and plots generated by the code to understand the performance of Sparse Autoencoders and k-means clustering.

* Remember to save your notebook periodically by clicking on "File" > "Save" or by using the keyboard shortcut Ctrl + S.

For any questions or issues, feel free to contact the author.

Author: Divya Rakheja

Contact: m22ai552@iitj.ac.in
